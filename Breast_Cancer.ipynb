{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPa4G3/BpD5eh2GbkElpzze"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":58,"metadata":{"id":"Jr3BHNBuu0Wd","executionInfo":{"status":"ok","timestamp":1694235984582,"user_tz":240,"elapsed":668,"user":{"displayName":"sachithra perera","userId":"02557196883860699593"}}},"outputs":[],"source":["# Importing libraries\n","import pandas as pd\n","import csv\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.linear_model import LogisticRegression\n","import seaborn as sns"]},{"cell_type":"code","source":["# Mounting the google drive\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","dp = \"/content/drive/MyDrive/ML/personalProject/data.txt\"\n","\n","with open(dp, 'r') as f:\n","    textLine = f.readlines()\n","    textLine = [line.strip().split(',') for line in textLine] # spltting data by comas\n","\n","\n","\n","# Now, 'text' contains the contents of the file\n","# print(text)\n"],"metadata":{"id":"wHtofhZeu_Wx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Writing into a csv file and saving them in the local area (in colab)\n","\n","# Defines attributes\n","attributes_names = ['class', 'age', 'menopause', 'tumor_size', 'inv_nodes', 'node_caps', 'deg_malig', 'breast', 'breast_quad', 'irradiat']\n","\n","# Defining output of the csv file\n","outPut = 'data.csv'\n","\n","# Add data to the csv file with attributes\n","with open(outPut, 'w', newline='') as csvfile:\n","  writer = csv.writer(csvfile)\n","  writer.writerow(attributes_names) # naming attributes\n","  writer.writerows(textLine) # writing data\n"],"metadata":{"id":"cCrAKR3u5i_7","executionInfo":{"status":"ok","timestamp":1694214431891,"user_tz":240,"elapsed":14,"user":{"displayName":"sachithra perera","userId":"02557196883860699593"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Reading the csv file into a dataframe\n","dataFrame = pd.read_csv(outPut)\n","\n","# remving rows that has missing values and represented by ?\n","dataFrame.replace('?', np.nan, inplace=True)\n","\n","# Removing rows with missing data in the dataframe\n","dataFrame = dataFrame.dropna()\n","\n","# Printing the entire data frame with index\n","print(dataFrame.to_string(index=False, max_rows=None))"],"metadata":{"id":"I5_FrdaaKOLg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Encoding\n","\n","# Create a new DataFrame with label encoded columns\n","encoded_df = dataFrame.copy()  # Make a copy of the original DataFrame\n","label_encoder = LabelEncoder()\n","\n","for column in attributes_names:\n","    encoded_df[column] = label_encoder.fit_transform(dataFrame[column])\n","\n","# print(encoded_df.to_string(index=False, max_rows=None))"],"metadata":{"id":"aOMSssHWYngB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting data into train and test.\n","# In here we define x and y.\n","# X --> independent variable [Features that excluding target variable]\n","# y --> depended variable [target variable]\n","\n","X = encoded_df.iloc[:,2:]\n","y = encoded_df.iloc[:,:1]\n","\n","y = np.array(y).flatten()\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"],"metadata":{"id":"4a75J0YOpkup","executionInfo":{"status":"ok","timestamp":1694232251964,"user_tz":240,"elapsed":149,"user":{"displayName":"sachithra perera","userId":"02557196883860699593"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Building the model using SVM classifier\n","\n","# Creating the classifier. There are four options to the kernel --> Linear, Polynomial, Gausian RBF, and Sigmoid\n","svm = SVC(kernel='rbf', C=10, gamma='auto')\n","\n","# Training the model\n","svm.fit(X_train,y_train)\n","\n","# Predicting\n","y_prediction = svm.predict(X_test)\n","\n","# Evaluating the model\n","accuracy = accuracy_score(y_test, y_prediction)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","print('Confusion Matrix:')\n","confusion = confusion_matrix(y_test, y_prediction)\n","print(confusion)\n","\n","print('Classification Report:')\n","print(classification_report(y_test, y_prediction))\n","\n","# Plot the confusion matrix with colors using seaborn and matplotlib\n","plt.figure(figsize=(8, 6))\n","sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"],"metadata":{"id":"7uz5uqmoF02e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building the model using LogisticRegression\n","\n","model = LogisticRegression()\n","\n","model.fit(X_train, y_train)\n","\n","y_pred = model.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy:.2f}')\n","\n","print('Confusion Matrix:')\n","print(confusion_matrix(y_test, y_pred))\n","\n","print('Classification Report:')\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"nq0AbwmIIYnK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cU6oAnPOMKVX"},"execution_count":null,"outputs":[]}]}